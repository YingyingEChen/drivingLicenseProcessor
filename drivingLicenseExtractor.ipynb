{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Extractor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and requirements\n",
    "### Enabling Document AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set to your designated project\n",
    "! gcloud config set project <PROJECT_ID>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enable the Document AI API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! gcloud services enable documentai.googleapis.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project setup\n",
    "Get project ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! gcloud config get-value core/project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a json file 'key.json' to store the service account key."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set environment variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PROJECT_ID'] = '<PROJECT_ID>'\n",
    "os.environ['SERVICE_ACCOUNT_NAME'] = 'documentai-processors'\n",
    "os.environ['SERVICE_ACCOUNT'] = f\"documentai-processors@{os.getenv('PROJECT_ID', '')}.iam.gserviceaccount.com\"\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = 'key.json' # path to json key file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Service Account and grant it \"Document AI Editor\" role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created service account [documentai-processors].\r\n"
     ]
    }
   ],
   "source": [
    "! gcloud iam service-accounts create documentai-processors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add documentai.editor and bigquery.dataEditor role to the service account:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "! gcloud projects add-iam-policy-binding $PROJECT_ID --member \"serviceAccount:$SERVICE_ACCOUNT\" \\\n",
    "                                                    --role \"roles/documentai.editor\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "! gcloud projects add-iam-policy-binding $PROJECT_ID --member \"serviceAccount:$SERVICE_ACCOUNT\" \\\n",
    "                                                    --role \"roles/bigquery.dataEditor\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! gcloud projects add-iam-policy-binding $PROJECT_ID --member \"serviceAccount:$SERVICE_ACCOUNT\" \\\n",
    "                                                    --role \"roles/bigquery.user\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create and dowload the service account key:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created key [2b0f6a5c376227feb74f1ba7da9f2356c604ab9d] of type [json] as [documentai-processors/key.json] for [documentai-processors@fraud-detection-python.iam.gserviceaccount.com]\r\n"
     ]
    }
   ],
   "source": [
    "! gcloud iam service-accounts keys create $GOOGLE_APPLICATION_CREDENTIALS --iam-account $SERVICE_ACCOUNT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "! cat $GOOGLE_APPLICATION_CREDENTIALS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python Setup\n",
    "Install required packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "! pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a custom processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.api_core.client_options import ClientOptions\n",
    "from google.cloud import documentai_v1 as documentai\n",
    "from google.api_core.exceptions import FailedPrecondition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = os.getenv(\"PROJECT_ID\", \"\")\n",
    "API_LOCATION = \"us\" # change to your document ai api location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_processor(display_name: str, type: str) -> documentai.Processor:\n",
    "    client_options = ClientOptions(\n",
    "        api_endpoint=f\"{API_LOCATION}-documentai.googleapis.com\"\n",
    "    )\n",
    "    client = documentai.DocumentProcessorServiceClient(client_options=client_options)\n",
    "    parent = client.common_location_path(PROJECT_ID, API_LOCATION)\n",
    "    processor = documentai.Processor(display_name=display_name, type_=type)\n",
    "    return client.create_processor(parent=parent, processor=processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name: \"projects/1014038123259/locations/us/processors/160d1359502b88e0\"\n",
       "type_: \"CUSTOM_EXTRACTION_PROCESSOR\"\n",
       "display_name: \"customProcessor\"\n",
       "state: ENABLED\n",
       "create_time {\n",
       "  seconds: 1665421935\n",
       "  nanos: 288389000\n",
       "}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_processor('customProcessor', 'CUSTOM_EXTRACTION_PROCESSOR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Processor\n",
    "### Upload Training and Testing Data\n",
    "Navigate to the custom processor detail page on cloud console.\n",
    "![Screenshot1](img/Screenshot1.png)\n",
    "\n",
    "Set the dataset location to a gcs bucket and click on ```CREATE DATA SET```.\n",
    "![Screenshot2.png](img/Screenshot2.png)\n",
    "\n",
    "Go to the gcs bucket and upload all the training and testing data in ```driving-license-train-data``` and ```driving-license-test-data``` folders.\n",
    "\n",
    "Go to the custom processor detail page and navigate to the 'Train' tab. Click on ```IMPORT DOCUMENTS``` and import all the data stored on the gcs bucket. In the ```Data split``` field, mark the data as 'Training' when upload the documents from the ```driving-license-train-data``` folder. Mark the data as 'Test' when uploading the documents from ```driving-license-test-data``` folder. In this demo, 10 documents have been used to train the processor, and 10 documents have been used to test it.\n",
    "![Screenshot4.png](img/Screenshot4.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labeling data\n",
    "Click on ```EDIT SCHEMA``` and add the followings labels by clicking ```CREATE LABEL```\n",
    "![Screenshot5](img/Screenshot5.png)\n",
    "\n",
    "Select one of the imported documents and label all the fields(Select the text on the image and choose the correct label). After identifying all the fields, click on ```MARK AS LABELLED```. All the imported documents need to be labelled before training the processor.\n",
    "![Screenshot6](img/Screenshot6.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trainning processor\n",
    "After labelling all the documents, click on \"TRAIN NEW VERSION\". Enter the version name, and click on \"START TRAINING\".\n",
    "![Screenshot7](img/Screenshot7.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploying processor\n",
    "After training is complete, go to the 'MANAGE VERSIONS' tab and deploy the trained version. Once the version has been deployed, an endpoint will be available under the 'PROCESSOR DETAILS' tab.\n",
    "![Screenshot8](img/Screenshot8.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process document using the trained processor\n",
    "Once the version has been deployed, copy the processor id to the ```PROCESSOR_ID``` field below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "PROJECT_ID = os.getenv(\"PROJECT_ID\", \"\") # change to your own project id\n",
    "LOCATION = 'us' # change to your document ai location\n",
    "MIME_TYPE = 'application/pdf' # document type\n",
    "PROCESSOR_ID = '16c52250499a3864' # change to the id of your trained processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Send the document for processing\n",
    "def send_processing_req(project_id, location, processor_id, file_path, mime_type, GCS_INPUT_URI = None):\n",
    "    \n",
    "    docai_client = documentai.DocumentProcessorServiceClient(\n",
    "        client_options = ClientOptions(api_endpoint=f'{location}-documentai.googleapis.com')\n",
    "    )\n",
    "\n",
    "    RESOURCE_NAME = docai_client.processor_path(project_id, location, processor_id)\n",
    "\n",
    "    # load file into memory\n",
    "    with open(file_path, 'rb') as image:\n",
    "        image_content = image.read()\n",
    "\n",
    "    raw_doc = documentai.RawDocument(content=image_content, mime_type=MIME_TYPE)\n",
    "    request = documentai.ProcessRequest(name=RESOURCE_NAME, raw_document=raw_doc)\n",
    "\n",
    "    result = docai_client.process_document(request=request)\n",
    "\n",
    "    document_object = result.document\n",
    "    print('Document processing complete')\n",
    "    # print(document_object.text)\n",
    "    return document_object\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pass the 'license.pdf' to the processor and a document object will be returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document processing complete\n"
     ]
    }
   ],
   "source": [
    "file_path = 'license.pdf'\n",
    "document_object = send_processing_req(PROJECT_ID, LOCATION, PROCESSOR_ID, file_path, MIME_TYPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text extracted from the document:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'UK\\nDRIVING LICENCE\\n1. MORGAN\\n2. SARAH\\nMEREDYTH\\n3. 11.03.1976 UNITED KINGDOM\\n4a. 19.01.2013 4c. DVLA\\n4b. 18.01.2023\\n5. MORGA753116SM9IJ 35\\nMPLE\\n*\\n7.\\nScamp\\n18.01.2023\\nISHI\\n122 BURNS CRESCENT\\nEDINBURGH\\nEH1 9GP\\n9. AM/A/B1/B/f/k/l/n/p/q\\nNEUROPEAN UNION MOCKS\\nDVLA INTERNAL USE\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_object.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fields and values identified by the trained processor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'address': '122 BURNS CRESCENT\\nEDINBURGH\\nEH1 9GP',\n",
       " 'date_of_expiry': '18.01.2023',\n",
       " 'date_of_issue': '19.01.2013',\n",
       " 'dob_pob': '11.03.1976 UNITED KINGDOM',\n",
       " 'first_name': 'SARAH\\nMEREDYTH',\n",
       " 'issued_by': 'DVLA',\n",
       " 'last_name': 'MORGAN',\n",
       " 'license_number': 'MORGA753116SM9IJ 35',\n",
       " 'type': 'AM/A/B1/B/f/k/l/n/p/q'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from results_to_bigquery import extract_document_entities\n",
    "extract_document_entities(document_object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output to Bigquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from results_to_bigquery import process_document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output the document ai object to Big Query. If you wish to store the output to a new table, change the ```TNTITIES_TABLE_NAME``` to a new table name. If the new table does not exist in the dataset, ```process_document``` will create a new table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME = 'document_extractor_results'\n",
    "ENTITIES_TABLE_NAME = 'driving_license_extracted_entities'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entities:  {'address': '122 BURNS CRESCENT\\nEDINBURGH\\nEH1 9GP', 'date_of_expiry': '18.01.2023', 'date_of_issue': '19.01.2013', 'dob_pob': '11.03.1976 UNITED KINGDOM', 'first_name': 'SARAH\\nMEREDYTH', 'issued_by': 'DVLA', 'last_name': 'MORGAN', 'license_number': 'MORGA753116SM9IJ 35', 'type': 'AM/A/B1/B/f/k/l/n/p/q', 'input_file_name': 'license.pdf', 'text': 'UK\\nDRIVING LICENCE\\n1. MORGAN\\n2. SARAH\\nMEREDYTH\\n3. 11.03.1976 UNITED KINGDOM\\n4a. 19.01.2013 4c. DVLA\\n4b. 18.01.2023\\n5. MORGA753116SM9IJ 35\\nMPLE\\n*\\n7.\\nScamp\\n18.01.2023\\nISHI\\n122 BURNS CRESCENT\\nEDINBURGH\\nEH1 9GP\\n9. AM/A/B1/B/f/k/l/n/p/q\\nNEUROPEAN UNION MOCKS\\nDVLA INTERNAL USE\\n'}\n",
      "Writing DocAI Entities to bq\n",
      "LoadJob<project=fraud-detection-python, location=US, id=4d010d2b-7093-40b3-ab11-16365cba9877>\n"
     ]
    }
   ],
   "source": [
    "process_document(document_object, file_path, DATASET_NAME, ENTITIES_TABLE_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidePrompt": true
   },
   "source": [
    "View the output result in BigQuery:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "\n",
    "# Construct a BigQuery client object.\n",
    "client = bigquery.Client()\n",
    "\n",
    "query = f\"\"\"\n",
    "    SELECT *\n",
    "    FROM `{PROJECT_ID}.{DATASET_NAME}.{ENTITIES_TABLE_NAME}`\n",
    "    LIMIT 20\n",
    "\"\"\"\n",
    "query_job = client.query(query)  # Make an API request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_file_name</th>\n",
       "      <th>type</th>\n",
       "      <th>issued_by</th>\n",
       "      <th>date_of_expiry</th>\n",
       "      <th>dob_pob</th>\n",
       "      <th>text</th>\n",
       "      <th>license_number</th>\n",
       "      <th>last_name</th>\n",
       "      <th>date_of_issue</th>\n",
       "      <th>first_name</th>\n",
       "      <th>address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>license.pdf</td>\n",
       "      <td>AM/A/B1/B/f/k/l/n/p/q</td>\n",
       "      <td>DVLA</td>\n",
       "      <td>18.01.2023</td>\n",
       "      <td>11.03.1976 UNITED KINGDOM</td>\n",
       "      <td>UK\\nDRIVING LICENCE\\n1. MORGAN\\n2. SARAH\\nMERE...</td>\n",
       "      <td>MORGA753116SM9IJ 35</td>\n",
       "      <td>MORGAN</td>\n",
       "      <td>19.01.2013</td>\n",
       "      <td>SARAH\\nMEREDYTH</td>\n",
       "      <td>122 BURNS CRESCENT\\nEDINBURGH\\nEH1 9GP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>license.pdf</td>\n",
       "      <td>AM/A/B1/B/f/k/l/n/p/q</td>\n",
       "      <td>DVLA</td>\n",
       "      <td>18.01.2023</td>\n",
       "      <td>11.03.1976 UNITED KINGDOM</td>\n",
       "      <td>UK\\nDRIVING LICENCE\\n1. MORGAN\\n2. SARAH\\nMERE...</td>\n",
       "      <td>MORGA753116SM9IJ 35</td>\n",
       "      <td>MORGAN</td>\n",
       "      <td>19.01.2013</td>\n",
       "      <td>SARAH\\nMEREDYTH</td>\n",
       "      <td>122 BURNS CRESCENT\\nEDINBURGH\\nEH1 9GP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  input_file_name                   type issued_by date_of_expiry  \\\n",
       "0     license.pdf  AM/A/B1/B/f/k/l/n/p/q      DVLA     18.01.2023   \n",
       "1     license.pdf  AM/A/B1/B/f/k/l/n/p/q      DVLA     18.01.2023   \n",
       "\n",
       "                     dob_pob  \\\n",
       "0  11.03.1976 UNITED KINGDOM   \n",
       "1  11.03.1976 UNITED KINGDOM   \n",
       "\n",
       "                                                text       license_number  \\\n",
       "0  UK\\nDRIVING LICENCE\\n1. MORGAN\\n2. SARAH\\nMERE...  MORGA753116SM9IJ 35   \n",
       "1  UK\\nDRIVING LICENCE\\n1. MORGAN\\n2. SARAH\\nMERE...  MORGA753116SM9IJ 35   \n",
       "\n",
       "  last_name date_of_issue       first_name  \\\n",
       "0    MORGAN    19.01.2013  SARAH\\nMEREDYTH   \n",
       "1    MORGAN    19.01.2013  SARAH\\nMEREDYTH   \n",
       "\n",
       "                                  address  \n",
       "0  122 BURNS CRESCENT\\nEDINBURGH\\nEH1 9GP  \n",
       "1  122 BURNS CRESCENT\\nEDINBURGH\\nEH1 9GP  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_job.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
